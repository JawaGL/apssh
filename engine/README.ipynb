{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the simplest possible coroutine for the sake of illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "async def mycoro(timeout):\n",
    "    print(\"-> {} mycoro({})\".format(time.strftime(\"%M-%S\"), timeout))\n",
    "    await asyncio.sleep(timeout)\n",
    "    print(\"<- {} mycoro({})\".format(time.strftime(\"%M-%S\"), timeout))\n",
    "    # return something easy to recognize\n",
    "    return 1000 * timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a series of coroutines in parallel - a la `gather` - can be done like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from job import Job\n",
    "from engine import Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1, a2, a3 = Job(mycoro(1)), Job(mycoro(2)), Job(mycoro(1.5)),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we're saying here is that we have three jobs, that have no relationships between them. \n",
    "\n",
    "So when we run them, we would start all 3 coroutines at once, and return once they are all done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduling job NO_LABEL\n",
      "scheduling job NO_LABEL\n",
      "scheduling job NO_LABEL\n",
      "-> 15-08 mycoro(1.5)\n",
      "-> 15-08 mycoro(1)\n",
      "-> 15-08 mycoro(2)\n",
      "<- 15-09 mycoro(1)\n",
      "<- 15-09 mycoro(1.5)\n",
      "<- 15-10 mycoro(2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = Engine(a1, a2, a3)\n",
    "e.orchestrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exemple 2 : add requirements (dependencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add *requirements* dependencies between jobs, like in the following example. We take this chance to show that jobs can be tagged with a label, which can turn out te be convenient somtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1, b2, b3 = (Job(mycoro(1), label=\"first\"),\n",
    "              Job(mycoro(2)), \n",
    "              Job(mycoro(1.5), label=\"last\"))\n",
    "\n",
    "b3.requires(b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `b3` needs `b1` to be finished before it can start. And so only the 2 first coroutines get started at the beginning, and only once b1 has finished does b3 start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scheduling job NO_LABEL\n",
      "scheduling job first\n",
      "-> 15-10 mycoro(2)\n",
      "-> 15-10 mycoro(1)\n",
      "<- 15-11 mycoro(1)\n",
      "scheduling job last\n",
      "-> 15-11 mycoro(1.5)\n",
      "<- 15-12 mycoro(2)\n",
      "<- 15-12 mycoro(1.5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e2 = Engine(b1, b2, b3)\n",
    "e2.orchestrate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing the `Job` class\n",
    "\n",
    "`Job` actually is a specializtion of `AbstractJob`, and the specification is that the `corun()` method should denote a coroutine itself, and that is what is triggered by `Engine` for running said job.\n",
    "\n",
    "You can define your own `Job` class by specializing `job.AbstractJob`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect results\n",
    "\n",
    "Details for each `Job` can be retrieved like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(b1.is_done())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500.0\n"
     ]
    }
   ],
   "source": [
    "print(b3.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Job `NO_LABEL' finished -> 2000>\n",
      "<Job `last' finished -> 1500.0 - [requires [first]]>\n",
      "<Job `first' finished -> 1000 - [allows [last]]>\n"
     ]
    }
   ],
   "source": [
    "for job in e2.jobs:\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "This totally is only a seed at this point, like day d+1 \n",
    "\n",
    "## termination\n",
    "* orchestrate should accept a timeout argument\n",
    "* some jobs are not designed to end. like, a monitoring tool that keeps on looking for a message queue and react.. It feels like if we provided a means to declare an `Job` as being such an never-ending loop, `orchestrate` would then be in a position to handle that gracefully.\n",
    "* provide a means to shutdown jobs once the engine has run out. Typically we would have several jobs using the same ssh connection, and these need to be closed at some point. Something like `Engine.shutdown` or similar.\n",
    "\n",
    "  Would it work to just send e.g. `coshutdown()` on all jobs ? this needs a little more thinking though; that could mean trying to shutdown an ssh connection from several points at the same time ...\n",
    "\n",
    "## deal with exceptions\n",
    "* for now we kind of assume that `corun()` does not trigger an exception. This needs to be robustified. \n",
    "\n",
    "## monitoring \n",
    "* come up with some basic (curses ?) monitor to show what's going on; what I have in mind is something like rhubarbe load where all jobs would be displayed, one line each, and their status could be shown so that one can get a sense of what is going on\n",
    "* one way to look at this is to have the main Engine class send itself a `tick()` method, and then specialize `Engine` as `EngineCurses` that would actually do things on such events.\n",
    "* ***or*** this gets delegated on a `message_queue` object. **Review the rhubarbe code on this aspect**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
